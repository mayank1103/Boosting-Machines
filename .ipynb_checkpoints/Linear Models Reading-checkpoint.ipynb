{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the theoretical background regarding these techniques , pleases refer to theoretical discussion on linear models. \n",
    "\n",
    "Now we'll discuss a case study solution using multiple linear regression, and regularised linear regresison [Ridge and Lasso] . We'll also look at hyper parameter tuning for regularised regression.\n",
    "\n",
    "A little background on the case study. This data belongs to a loan aggregator agency which connects loan applications to different financial institutions in attempt to get the best interest rate. They want to now utilise past data to predict interest rate given by any financial institute just by looking at loan application characteristics.\n",
    "\n",
    "To achieve that , they have decided to do a POC with a data from a particular financial institution. The data is given in the file \"loans data.csv\". Lets begin: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file='C:/R/Data/loans data.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline\n",
    "\n",
    "ld=pd.read_csv(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Amount.Requested</th>\n",
       "      <th>Amount.Funded.By.Investors</th>\n",
       "      <th>Interest.Rate</th>\n",
       "      <th>Loan.Length</th>\n",
       "      <th>Loan.Purpose</th>\n",
       "      <th>Debt.To.Income.Ratio</th>\n",
       "      <th>State</th>\n",
       "      <th>Home.Ownership</th>\n",
       "      <th>Monthly.Income</th>\n",
       "      <th>FICO.Range</th>\n",
       "      <th>Open.CREDIT.Lines</th>\n",
       "      <th>Revolving.CREDIT.Balance</th>\n",
       "      <th>Inquiries.in.the.Last.6.Months</th>\n",
       "      <th>Employment.Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81174.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>8.90%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>14.90%</td>\n",
       "      <td>SC</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>6541.67</td>\n",
       "      <td>735-739</td>\n",
       "      <td>14</td>\n",
       "      <td>14272</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99592.0</td>\n",
       "      <td>19200</td>\n",
       "      <td>19200</td>\n",
       "      <td>12.12%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>28.36%</td>\n",
       "      <td>TX</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>4583.33</td>\n",
       "      <td>715-719</td>\n",
       "      <td>12</td>\n",
       "      <td>11140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80059.0</td>\n",
       "      <td>35000</td>\n",
       "      <td>35000</td>\n",
       "      <td>21.98%</td>\n",
       "      <td>60 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>23.81%</td>\n",
       "      <td>CA</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>11500.00</td>\n",
       "      <td>690-694</td>\n",
       "      <td>14</td>\n",
       "      <td>21977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15825.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>9975</td>\n",
       "      <td>9.99%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>14.30%</td>\n",
       "      <td>KS</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>3833.33</td>\n",
       "      <td>695-699</td>\n",
       "      <td>10</td>\n",
       "      <td>9346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33182.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.71%</td>\n",
       "      <td>36 months</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>18.78%</td>\n",
       "      <td>NJ</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3195.00</td>\n",
       "      <td>695-699</td>\n",
       "      <td>11</td>\n",
       "      <td>14469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9 years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Amount.Requested Amount.Funded.By.Investors Interest.Rate  \\\n",
       "0  81174.0            20000                      20000         8.90%   \n",
       "1  99592.0            19200                      19200        12.12%   \n",
       "2  80059.0            35000                      35000        21.98%   \n",
       "3  15825.0            10000                       9975         9.99%   \n",
       "4  33182.0            12000                      12000        11.71%   \n",
       "\n",
       "  Loan.Length        Loan.Purpose Debt.To.Income.Ratio State Home.Ownership  \\\n",
       "0   36 months  debt_consolidation               14.90%    SC       MORTGAGE   \n",
       "1   36 months  debt_consolidation               28.36%    TX       MORTGAGE   \n",
       "2   60 months  debt_consolidation               23.81%    CA       MORTGAGE   \n",
       "3   36 months  debt_consolidation               14.30%    KS       MORTGAGE   \n",
       "4   36 months         credit_card               18.78%    NJ           RENT   \n",
       "\n",
       "   Monthly.Income FICO.Range Open.CREDIT.Lines Revolving.CREDIT.Balance  \\\n",
       "0         6541.67    735-739                14                    14272   \n",
       "1         4583.33    715-719                12                    11140   \n",
       "2        11500.00    690-694                14                    21977   \n",
       "3         3833.33    695-699                10                     9346   \n",
       "4         3195.00    695-699                11                    14469   \n",
       "\n",
       "   Inquiries.in.the.Last.6.Months Employment.Length  \n",
       "0                             2.0          < 1 year  \n",
       "1                             1.0           2 years  \n",
       "2                             1.0           2 years  \n",
       "3                             0.0           5 years  \n",
       "4                             0.0           9 years  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that variable Interest.Rate and Debt.To.Income.Ratio contain \"%\" sign in their values and because of which they have come as character columns in the data. Lets remove these percentages first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Interest.Rate\",\"Debt.To.Income.Ratio\"]:\n",
    "    ld[col]=ld[col].astype(\"str\")\n",
    "    ld[col]=[x.replace(\"%\",\"\") for x in ld[col]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                float64\n",
       "Amount.Requested                   object\n",
       "Amount.Funded.By.Investors         object\n",
       "Interest.Rate                      object\n",
       "Loan.Length                        object\n",
       "Loan.Purpose                       object\n",
       "Debt.To.Income.Ratio               object\n",
       "State                              object\n",
       "Home.Ownership                     object\n",
       "Monthly.Income                    float64\n",
       "FICO.Range                         object\n",
       "Open.CREDIT.Lines                  object\n",
       "Revolving.CREDIT.Balance           object\n",
       "Inquiries.in.the.Last.6.Months    float64\n",
       "Employment.Length                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that many columns which should have really been numbers have been imported as character columns , probably because some characters values in those columns in the files. We'll convert all such columns to numbers ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Amount.Requested\",\"Amount.Funded.By.Investors\",\"Open.CREDIT.Lines\",\"Revolving.CREDIT.Balance\",\n",
    "           \"Inquiries.in.the.Last.6.Months\",\"Interest.Rate\",\"Debt.To.Income.Ratio\"]:\n",
    "    ld[col]=pd.to_numeric(ld[col],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                float64\n",
       "Amount.Requested                  float64\n",
       "Amount.Funded.By.Investors        float64\n",
       "Interest.Rate                     float64\n",
       "Loan.Length                        object\n",
       "Loan.Purpose                       object\n",
       "Debt.To.Income.Ratio              float64\n",
       "State                              object\n",
       "Home.Ownership                     object\n",
       "Monthly.Income                    float64\n",
       "FICO.Range                         object\n",
       "Open.CREDIT.Lines                 float64\n",
       "Revolving.CREDIT.Balance          float64\n",
       "Inquiries.in.the.Last.6.Months    float64\n",
       "Employment.Length                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will make dummy variables for remaining categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36 months    1950\n",
       "60 months     548\n",
       ".               1\n",
       "Name: Loan.Length, dtype: int64"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld[\"Loan.Length\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function get_dummies creates dummy variables for all the categories present in the categorical variable. Result is a dataframe, we can then choose and drop the dummies that we want to drop and attach the ones selected back to our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_dummies=pd.get_dummies(ld[\"Loan.Length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>36 months</th>\n",
       "      <th>60 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   .  36 months  60 months\n",
       "0  0          1          0\n",
       "1  0          1          0\n",
       "2  0          0          1\n",
       "3  0          1          0\n",
       "4  0          1          0"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add dummy variable for \"36 months\" to our data and ignore the rest two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld[\"LL_36\"]=ll_dummies[\"36 months\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we'are done with dataframe ll_dummies , we can drop it. Below we demonstrate a general way of removing variables from notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset_selective ll_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know what all variables are in the environment, you can use function \"who\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN\t FP\t Fbeta_perf\t KFold\t KS\t KS_cut\t KS_cutoff\t Lasso\t LinearRegression\t \n",
      "LogisticRegression\t N\t P\t Ridge\t TN\t TP\t a\t ab_dummies\t alphas\t \n",
      "bd\t bd_test\t bd_train\t best_alpha\t coefs\t col\t cutoff\t cutoff_data\t cutoffs\t \n",
      "data_file\t df\t df_test\t err\t features\t i\t k\t kf\t lasso\t \n",
      "ld\t ld_test\t ld_train\t list\t lm\t logr\t lp_dummies\t lst\t math\t \n",
      "np\t oc_dummies\t p\t p_test\t pd\t predicted\t predicted_test\t prob_score\t prob_score_test\t \n",
      "residual\t ridge\t rmse_10cv\t rmse_lasso\t rmse_list\t rmse_lm\t rmse_ridge\t roc_auc_score\t test\t \n",
      "train\t train_test_split\t x_test\t x_train\t xval_err\t y_test\t y_train\t \n"
     ]
    }
   ],
   "source": [
    "who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created dummies for Loan.Length, we need to remove this from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld=ld.drop('Loan.Length',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                float64\n",
       "Amount.Requested                  float64\n",
       "Amount.Funded.By.Investors        float64\n",
       "Interest.Rate                     float64\n",
       "Loan.Purpose                       object\n",
       "Debt.To.Income.Ratio              float64\n",
       "State                              object\n",
       "Home.Ownership                     object\n",
       "Monthly.Income                    float64\n",
       "FICO.Range                         object\n",
       "Open.CREDIT.Lines                 float64\n",
       "Revolving.CREDIT.Balance          float64\n",
       "Inquiries.in.the.Last.6.Months    float64\n",
       "Employment.Length                  object\n",
       "LL_36                               uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we examine variable \"Loan.Purpose\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debt_consolidation    1307\n",
       "credit_card            444\n",
       "other                  200\n",
       "home_improvement       152\n",
       "major_purchase         101\n",
       "small_business          87\n",
       "car                     50\n",
       "wedding                 39\n",
       "medical                 30\n",
       "moving                  29\n",
       "vacation                21\n",
       "house                   20\n",
       "educational             15\n",
       "renewable_energy         4\n",
       "Name: Loan.Purpose, dtype: int64"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld[\"Loan.Purpose\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 14 categories in that variable, we can either make 13 dummies or we can club few of these categories together and reduce the number of effective categories and then make dummy variables for those.\n",
    "\n",
    "It makes sense to club those categories which behave similarly in terms of their effect on response. Or in other words , we can club those categories for which average interest rates are similar in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan.Purpose\n",
       "car                   11.0\n",
       "credit_card           13.0\n",
       "debt_consolidation    14.0\n",
       "educational           11.0\n",
       "home_improvement      12.0\n",
       "house                 13.0\n",
       "major_purchase        11.0\n",
       "medical               12.0\n",
       "moving                14.0\n",
       "other                 13.0\n",
       "renewable_energy      10.0\n",
       "small_business        13.0\n",
       "vacation              12.0\n",
       "wedding               12.0\n",
       "Name: Interest.Rate, dtype: float64"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ld.groupby(\"Loan.Purpose\")[\"Interest.Rate\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the table above that there are 4 effective categoris in the data. Lets club them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ld.index)):\n",
    "    if ld[\"Loan.Purpose\"][i] in [\"car\",\"educational\",\"major_purchase\"]:\n",
    "        ld.loc[i,\"Loan.Purpose\"]=\"cem\"\n",
    "    if ld[\"Loan.Purpose\"][i] in [\"home_improvement\",\"medical\",\"vacation\",\"wedding\"]:\n",
    "        ld.loc[i,\"Loan.Purpose\"]=\"hmvw\"\n",
    "    if ld[\"Loan.Purpose\"][i] in [\"credit_card\",\"house\",\"other\",\"small_business\"]:\n",
    "        ld.loc[i,\"Loan.Purpose\"]=\"chos\"\n",
    "    if ld[\"Loan.Purpose\"][i] in [\"debt_consolidation\",\"moving\"]:\n",
    "        ld.loc[i,\"Loan.Purpose\"]=\"dm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make dummies for this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_dummies=pd.get_dummies(ld[\"Loan.Purpose\"],prefix=\"LP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LP_cem</th>\n",
       "      <th>LP_chos</th>\n",
       "      <th>LP_dm</th>\n",
       "      <th>LP_hmvw</th>\n",
       "      <th>LP_renewable_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LP_cem  LP_chos  LP_dm  LP_hmvw  LP_renewable_energy\n",
       "0       0        0      1        0                    0\n",
       "1       0        0      1        0                    0\n",
       "2       0        0      1        0                    0\n",
       "3       0        0      1        0                    0\n",
       "4       0        1      0        0                    0"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add this data to original data. And then drop original variable \"Loan.Purpose\" and one of the dummies \"LP_renewable_energy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld=pd.concat([ld,lp_dummies],1)\n",
    "ld=ld.drop([\"Loan.Purpose\",\"LP_renewable_energy\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                float64\n",
       "Amount.Requested                  float64\n",
       "Amount.Funded.By.Investors        float64\n",
       "Interest.Rate                     float64\n",
       "Debt.To.Income.Ratio              float64\n",
       "State                              object\n",
       "Home.Ownership                     object\n",
       "Monthly.Income                    float64\n",
       "FICO.Range                         object\n",
       "Open.CREDIT.Lines                 float64\n",
       "Revolving.CREDIT.Balance          float64\n",
       "Inquiries.in.the.Last.6.Months    float64\n",
       "Employment.Length                  object\n",
       "LL_36                               uint8\n",
       "LP_cem                              uint8\n",
       "LP_chos                             uint8\n",
       "LP_dm                               uint8\n",
       "LP_hmvw                             uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at variable \"State\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld[\"State\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many unique values. Although its not a legit reason to drop a variable. But we'll ignore this in this discussion any way in order to reduce amount of data prep that we are doing here. You can try including it in the model and see if the performance improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld=ld.drop([\"State\"],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we take care of variable Home.Ownership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MORTGAGE    1147\n",
       "RENT        1146\n",
       "OWN          200\n",
       "OTHER          5\n",
       "NONE           1\n",
       "Name: Home.Ownership, dtype: int64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld[\"Home.Ownership\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld[\"ho_mort\"]=np.where(ld[\"Home.Ownership\"]==\"MORTGAGE\",1,0)\n",
    "ld[\"ho_rent\"]=np.where(ld[\"Home.Ownership\"]==\"RENT\",1,0)\n",
    "ld=ld.drop([\"Home.Ownership\"],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have simply ignored values OTHER and NONE , and considered that there are only 3 categories and created only two dummies . We did this because of very low frequencies of OTHER and NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    735-739\n",
       "1    715-719\n",
       "2    690-694\n",
       "3    695-699\n",
       "4    695-699\n",
       "Name: FICO.Range, dtype: object"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld[\"FICO.Range\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at first few values of variable FICO.Range , you can see that we can convert it to numeric by taking average of the range given. To do that first we need to split the column with \"-\", so that we can have both end of ranges in separate columns and then we can simply average them.\n",
    "Lets first split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld['f1'], ld['f2'] = zip(*ld['FICO.Range'].apply(lambda x: x.split('-', 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create new variable \"fico\" by averaging f1 and f2. And then we'll drop the original variable FICO.Range and f1,f2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld[\"fico\"]=0.5*(pd.to_numeric(ld[\"f1\"])+pd.to_numeric(ld[\"f2\"]))\n",
    "\n",
    "ld=ld.drop([\"FICO.Range\",\"f1\",\"f2\"],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at variavle Employment.Length. You'll see that we can convert that to number as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10+ years    653\n",
       "< 1 year     249\n",
       "2 years      243\n",
       "3 years      235\n",
       "5 years      202\n",
       "4 years      191\n",
       "1 year       177\n",
       "6 years      163\n",
       "7 years      127\n",
       "8 years      108\n",
       "9 years       72\n",
       ".              2\n",
       "Name: Employment.Length, dtype: int64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld[\"Employment.Length\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld[\"Employment.Length\"]=ld[\"Employment.Length\"].astype(\"str\")\n",
    "ld[\"Employment.Length\"]=[x.replace(\"years\",\"\") for x in ld[\"Employment.Length\"]]\n",
    "ld[\"Employment.Length\"]=[x.replace(\"year\",\"\") for x in ld[\"Employment.Length\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert everything else to numbers , but \"n/a\" are a problem. We can look at average interest across all values of Employment.Length and then replace \"n/a\" with value which has closet average response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employment.Length\n",
       ".       11.34\n",
       "1       12.49\n",
       "10+     13.34\n",
       "2       12.87\n",
       "3       12.77\n",
       "4       13.14\n",
       "5       13.40\n",
       "6       13.29\n",
       "7       13.10\n",
       "8       13.01\n",
       "9       13.15\n",
       "< 1     12.86\n",
       "nan     12.78\n",
       "Name: Interest.Rate, dtype: float64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ld.groupby(\"Employment.Length\")[\"Interest.Rate\"].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see \"n/a\" is similar to \"< 1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld[\"Employment.Length\"]=[x.replace(\"n/a\",\"< 1\") for x in ld[\"Employment.Length\"]]\n",
    "ld[\"Employment.Length\"]=[x.replace(\"10+\",\"10\") for x in ld[\"Employment.Length\"]]\n",
    "ld[\"Employment.Length\"]=[x.replace(\"< 1\",\"0\") for x in ld[\"Employment.Length\"]]\n",
    "ld[\"Employment.Length\"]=pd.to_numeric(ld[\"Employment.Length\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                float64\n",
       "Amount.Requested                  float64\n",
       "Amount.Funded.By.Investors        float64\n",
       "Interest.Rate                     float64\n",
       "Debt.To.Income.Ratio              float64\n",
       "Monthly.Income                    float64\n",
       "Open.CREDIT.Lines                 float64\n",
       "Revolving.CREDIT.Balance          float64\n",
       "Inquiries.in.the.Last.6.Months    float64\n",
       "Employment.Length                 float64\n",
       "LL_36                               uint8\n",
       "LP_cem                              uint8\n",
       "LP_chos                             uint8\n",
       "LP_dm                               uint8\n",
       "LP_hmvw                             uint8\n",
       "ho_mort                             int32\n",
       "ho_rent                             int32\n",
       "fico                              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the variables as numbers. After dropping observations with missing values , we can proceed to build oru model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 18)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2394, 18)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split our data into two random parts . One to build model on , Another to test its performance. Option \"random_state\" is used to make our random operation reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_train, ld_test = train_test_split(ld, test_size = 0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above line creates and object of class LinearRegression named lm. We can use this object to access all functions realted to LinearRegression.\n",
    "\n",
    "Now we'll separate predictors and response for both the datasets . We'll also drop ID from predictor's list because it doesnt make sense to include an ID variable in the model. Variable \"Amount.Funded.By.Investors\" will also be dropped because it wont be available until the loan has been processed. We can use only those variables which are present at the point of the business process where we want to apply our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=ld_train.drop([\"Interest.Rate\",\"ID\",\"Amount.Funded.By.Investors\"],1)\n",
    "y_train=ld_train[\"Interest.Rate\"]\n",
    "x_test=ld_test.drop([\"Interest.Rate\",\"ID\",\"Amount.Funded.By.Investors\"],1)\n",
    "y_test=ld_test[\"Interest.Rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit our model using lm the LinearRegression object that we created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we predict resposne on our test data , calculate errors on those prediction and then rmse for those residuals. That is the measure of performance on the test data. We can use this measure to compare other models that we'll build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9931900065094665"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test=lm.predict(x_test)\n",
    "\n",
    "residual=p_test-y_test\n",
    "\n",
    "rmse_lm=np.sqrt(np.dot(residual,residual)/len(p_test))\n",
    "\n",
    "rmse_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to compare our linear regression model with other techniques and evenutall pick the one with least error ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we show how to extract coefficient produced by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-370-2e9cb0f75fec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "coefs=lm.coef_\n",
    "\n",
    "features=x_train.columns\n",
    "\n",
    "list(zip(features,coefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that linear regression has produced coefficients for all variables. If you recall our theoretical discussion, we need to penalise coefficient for the variables which are not really contributing well to our resposne and might be causing overfitting of the model. Among the regularised technique we'll first look at Ridge regression.\n",
    "\n",
    "Since penalty in ridge regression is a hyperparameter , we'd look at multiple values of it and choose the best one through 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding best value of penalty weight with cross validation for ridge regression\n",
    "alphas=np.linspace(.0001,10,100)\n",
    "# We need to reset index for cross validation to work without hitch\n",
    "x_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 1.01109091e-01, 2.02118182e-01, 3.03127273e-01,\n",
       "       4.04136364e-01, 5.05145455e-01, 6.06154545e-01, 7.07163636e-01,\n",
       "       8.08172727e-01, 9.09181818e-01, 1.01019091e+00, 1.11120000e+00,\n",
       "       1.21220909e+00, 1.31321818e+00, 1.41422727e+00, 1.51523636e+00,\n",
       "       1.61624545e+00, 1.71725455e+00, 1.81826364e+00, 1.91927273e+00,\n",
       "       2.02028182e+00, 2.12129091e+00, 2.22230000e+00, 2.32330909e+00,\n",
       "       2.42431818e+00, 2.52532727e+00, 2.62633636e+00, 2.72734545e+00,\n",
       "       2.82835455e+00, 2.92936364e+00, 3.03037273e+00, 3.13138182e+00,\n",
       "       3.23239091e+00, 3.33340000e+00, 3.43440909e+00, 3.53541818e+00,\n",
       "       3.63642727e+00, 3.73743636e+00, 3.83844545e+00, 3.93945455e+00,\n",
       "       4.04046364e+00, 4.14147273e+00, 4.24248182e+00, 4.34349091e+00,\n",
       "       4.44450000e+00, 4.54550909e+00, 4.64651818e+00, 4.74752727e+00,\n",
       "       4.84853636e+00, 4.94954545e+00, 5.05055455e+00, 5.15156364e+00,\n",
       "       5.25257273e+00, 5.35358182e+00, 5.45459091e+00, 5.55560000e+00,\n",
       "       5.65660909e+00, 5.75761818e+00, 5.85862727e+00, 5.95963636e+00,\n",
       "       6.06064545e+00, 6.16165455e+00, 6.26266364e+00, 6.36367273e+00,\n",
       "       6.46468182e+00, 6.56569091e+00, 6.66670000e+00, 6.76770909e+00,\n",
       "       6.86871818e+00, 6.96972727e+00, 7.07073636e+00, 7.17174545e+00,\n",
       "       7.27275455e+00, 7.37376364e+00, 7.47477273e+00, 7.57578182e+00,\n",
       "       7.67679091e+00, 7.77780000e+00, 7.87880909e+00, 7.97981818e+00,\n",
       "       8.08082727e+00, 8.18183636e+00, 8.28284545e+00, 8.38385455e+00,\n",
       "       8.48486364e+00, 8.58587273e+00, 8.68688182e+00, 8.78789091e+00,\n",
       "       8.88890000e+00, 8.98990909e+00, 9.09091818e+00, 9.19192727e+00,\n",
       "       9.29293636e+00, 9.39394545e+00, 9.49495455e+00, 9.59596364e+00,\n",
       "       9.69697273e+00, 9.79798182e+00, 9.89899091e+00, 1.00000000e+01])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 192  193  194 ... 1912 1913 1914]\n",
      "[   0    1    2 ... 1912 1913 1914]\n",
      "[   0    1    2 ... 1912 1913 1914]\n",
      "[   0    1    2 ... 1912 1913 1914]\n",
      "[   0    1    2 ... 1912 1913 1914]\n",
      "[   0    1    2 ... 1912 1913 1914]\n",
      "[   0    1    2 ... 1912 1913 1914]\n",
      "[   0    1    2 ... 1912 1913 1914]\n",
      "[   0    1    2 ... 1912 1913 1914]\n",
      "[   0    1    2 ... 1721 1722 1723]\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=10)\n",
    "for train, test in kf.split(x_train):\n",
    "    print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha with min 10cv error is :  [0.0001]\n"
     ]
    }
   ],
   "source": [
    "rmse_list=[]\n",
    "for a in alphas:\n",
    "    ridge = Ridge(fit_intercept=True, alpha=a)\n",
    "\n",
    "    # computing average RMSE across 10-fold cross validation\n",
    "    kf = KFold(n_splits=10)\n",
    "    xval_err = 0 #this is due to we will get 10 xval error for each kfold so we need min alpha value.to get tht we set it 0.\n",
    "    for train, test in kf.split(x_train):\n",
    "        ridge.fit(x_train.iloc[train], y_train.iloc[train])\n",
    "        p = ridge.predict(x_train.iloc[test])\n",
    "        err = p - y_train[test]\n",
    "        xval_err += np.dot(err,err)\n",
    "    rmse_10cv = np.sqrt(xval_err/len(x_train))\n",
    "    # uncomment below to print rmse values for individidual alphas\n",
    "#     print('{:.3f}\\t {:.6f}\\t '.format(a,rmse_10cv))\n",
    "    rmse_list.extend([rmse_10cv])\n",
    "best_alpha=alphas[rmse_list==min(rmse_list)]\n",
    "print('Alpha with min 10cv error is : ',best_alpha )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best value of alpha  might be slightly different across different runs because of random nature of cross validation. So dont worry if you determine a different value of best alpha.\n",
    "\n",
    "Next we fit Ridge Regression on the entire train data with best value of alpha we just determined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9931889069085253"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ridge=Ridge(fit_intercept=True,alpha=best_alpha)\n",
    "\n",
    "ridge.fit(x_train,y_train)\n",
    "\n",
    "p_test=ridge.predict(x_test)\n",
    "\n",
    "residual=p_test-y_test\n",
    "\n",
    "rmse_ridge=np.sqrt(np.dot(residual,residual)/len(p_test))\n",
    "\n",
    "rmse_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-376-3700702610b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "list(zip(x_train.columns,ridge.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(features,coefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that ridge regression though, shrinks the coefficients but never makes them exactly zero, essentially never reduce our model size. Next we look at lasso Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=np.linspace(0.0001,10,100)\n",
    "rmse_list=[]\n",
    "for a in alphas:\n",
    "    lasso = Lasso(fit_intercept=True, alpha=a,max_iter=10000)\n",
    "    kf = KFold(n_splits=10) \n",
    "    # computing RMSE using 10-fold cross validation\n",
    "    xval_err = 0\n",
    "    for train, test in kf.split(x_train):\n",
    "        lasso.fit(x_train.iloc[train], y_train.iloc[train])\n",
    "        p =lasso.predict(x_train.iloc[test])\n",
    "        err = p - y_train[test]\n",
    "        xval_err += np.dot(err,err)\n",
    "    rmse_10cv = np.sqrt(xval_err/len(x_train))\n",
    "    rmse_list.extend([rmse_10cv])\n",
    "    # Uncomment below to print rmse values of individual alphas\n",
    "    print('{:.3f}\\t {:.4f}\\t '.format(a,rmse_10cv))\n",
    "best_alpha=alphas[rmse_list==min(rmse_list)]\n",
    "print('Alpha with min 10cv error is : ',best_alpha )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso=Lasso(fit_intercept=True,alpha=best_alpha)\n",
    "\n",
    "lasso.fit(x_train,y_train)\n",
    "\n",
    "p_test=lasso.predict(x_test)\n",
    "\n",
    "residual=p_test-y_test\n",
    "\n",
    "rmse_lasso=np.sqrt(np.dot(residual,residual)/len(p_test))\n",
    "\n",
    "rmse_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(x_train.columns,lasso.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that lasso regression, not only improves performance on the data slightly , but also makes size of the model smaller by making many coefficents exactly zero, thus excluding them from our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model for Binary Classification\n",
    "\n",
    "A retail banking institution is going to float a stock trading facility for their existing customer. Since this kind of facitlity is nothing new , company knows that they will have to incetivise their customers for adopting their offerings. One way to incetiwise is to offer discounts on the commision for trading transactions.\n",
    "\n",
    "One issue with that is that only about 10% of the customers do enought trades for earnings after discounts to be profitable. Company wants to figure out, which are those 10% customer so that it can selectively offer them discount. there is no magic way to figure that out. So company rolled out this service to about 10000+ of their customers and observed their trading behaviour for 6 months and after that they labelled them into two revenue.grids 1 and 2.\n",
    "using this data, now they want us to build a classification model which can be used to classify their remaining customers into these revenue grids.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression from Scikit Learn \n",
    "\n",
    "Logistic Regression in scikit learn already contains penalties. l1 and l2 [Read as L-one & L-two] penalties . l1 penalty is same as lasso penalty where as l2 is same as ridge penalty. parameter C for logistic regression function is the hyperparameter for penalty . However it works in inverse fashion, i.e. if C takes smalle , it means higher penalty. \n",
    "\n",
    "For the case that we have discussed here , we have discussed l1 penalty with value of C as 1. We have left following things for you to try on your own.\n",
    "\n",
    "* model with l2 penalty\n",
    "* Finding optimal value of hyperparameter C with cross-validation for both the penalties\n",
    "\n",
    "You will find these in the practice exercise as well\n",
    "\n",
    "you can use auc value obtained from function roc_auc_score to select best value for the hyperparameter. Higher the auc, better is the model . If you dont recall this, please go back to the theoretical reading material.\n",
    "\n",
    "Lets beging our model building process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file='C:/R/Data/Existing Base.csv'\n",
    "bd=pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REF_NO</th>\n",
       "      <th>children</th>\n",
       "      <th>age_band</th>\n",
       "      <th>status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_partner</th>\n",
       "      <th>home_status</th>\n",
       "      <th>family_income</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>self_employed_partner</th>\n",
       "      <th>...</th>\n",
       "      <th>Investment Tax Saving Bond</th>\n",
       "      <th>Home Loan</th>\n",
       "      <th>Online Purchase Amount</th>\n",
       "      <th>Revenue Grid</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>Investment in Commudity</th>\n",
       "      <th>Investment in Equity</th>\n",
       "      <th>Investment in Derivative</th>\n",
       "      <th>Portfolio Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Zero</td>\n",
       "      <td>51-55</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Manual Worker</td>\n",
       "      <td>Secretarial/Admin</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;17,500, &gt;=15,000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Wales</td>\n",
       "      <td>74.67</td>\n",
       "      <td>18.66</td>\n",
       "      <td>32.32</td>\n",
       "      <td>89.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Zero</td>\n",
       "      <td>55-60</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;27,500, &gt;=25,000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>North West</td>\n",
       "      <td>20.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>22.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Zero</td>\n",
       "      <td>26-30</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Other</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;30,000, &gt;=27,500</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>North</td>\n",
       "      <td>98.06</td>\n",
       "      <td>31.07</td>\n",
       "      <td>80.96</td>\n",
       "      <td>171.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Zero</td>\n",
       "      <td>18-21</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Manual Worker</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;15,000, &gt;=12,500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>4.10</td>\n",
       "      <td>14.15</td>\n",
       "      <td>17.57</td>\n",
       "      <td>-41.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Zero</td>\n",
       "      <td>45-50</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Business Manager</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;30,000, &gt;=27,500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.91</td>\n",
       "      <td>25.98</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>70.16</td>\n",
       "      <td>55.86</td>\n",
       "      <td>80.44</td>\n",
       "      <td>235.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   REF_NO children age_band                status        occupation  \\\n",
       "0       1     Zero    51-55               Partner     Manual Worker   \n",
       "1       2     Zero    55-60  Single/Never Married           Retired   \n",
       "2       3     Zero    26-30  Single/Never Married      Professional   \n",
       "3       5     Zero    18-21  Single/Never Married      Professional   \n",
       "4       6     Zero    45-50               Partner  Business Manager   \n",
       "\n",
       "  occupation_partner home_status      family_income self_employed  \\\n",
       "0  Secretarial/Admin    Own Home  <17,500, >=15,000            No   \n",
       "1            Retired    Own Home  <27,500, >=25,000            No   \n",
       "2              Other    Own Home  <30,000, >=27,500           Yes   \n",
       "3      Manual Worker    Own Home  <15,000, >=12,500            No   \n",
       "4            Unknown    Own Home  <30,000, >=27,500            No   \n",
       "\n",
       "  self_employed_partner        ...          Investment Tax Saving Bond  \\\n",
       "0                    No        ...                               19.99   \n",
       "1                    No        ...                                0.00   \n",
       "2                    No        ...                                0.00   \n",
       "3                    No        ...                                0.00   \n",
       "4                    No        ...                                0.00   \n",
       "\n",
       "  Home Loan Online Purchase Amount Revenue Grid  gender         region  \\\n",
       "0      0.00                   0.00            1  Female          Wales   \n",
       "1      0.00                   0.00            2  Female     North West   \n",
       "2      3.49                   0.00            2    Male          North   \n",
       "3      0.00                   0.00            2  Female  West Midlands   \n",
       "4     45.91                  25.98            2  Female       Scotland   \n",
       "\n",
       "   Investment in Commudity  Investment in Equity  Investment in Derivative  \\\n",
       "0                    74.67                 18.66                     32.32   \n",
       "1                    20.19                  0.00                      4.33   \n",
       "2                    98.06                 31.07                     80.96   \n",
       "3                     4.10                 14.15                     17.57   \n",
       "4                    70.16                 55.86                     80.44   \n",
       "\n",
       "   Portfolio Balance  \n",
       "0              89.43  \n",
       "1              22.78  \n",
       "2             171.78  \n",
       "3             -41.70  \n",
       "4             235.02  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zero    6208\n",
       "1       1848\n",
       "2       1607\n",
       "3        473\n",
       "4+        19\n",
       "Name: children, dtype: int64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd[\"children\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we can directly convert this to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.loc[bd[\"children\"]==\"Zero\",\"children\"]=\"0\"\n",
    "bd.loc[bd[\"children\"]==\"4+\",\"children\"]=\"4\"\n",
    "bd[\"children\"]=pd.to_numeric(bd[\"children\"],errors=\"coerce\") #coerce ignore any character and add NA instead of missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    9069\n",
       "1    1086\n",
       "Name: Revenue Grid, dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd[\"Revenue Grid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd[\"y\"]=np.where(bd[\"Revenue Grid\"]==2,0,1)\n",
    "bd=bd.drop([\"Revenue Grid\"],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For variable , age_band if we treat it as categorical variable , we can combine its categories by looking average response rate across its categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_band\n",
       "18-21      0.17\n",
       "22-25      0.11\n",
       "26-30      0.11\n",
       "31-35      0.11\n",
       "36-40      0.13\n",
       "41-45      0.11\n",
       "45-50      0.10\n",
       "51-55      0.10\n",
       "55-60      0.11\n",
       "61-65      0.09\n",
       "65-70      0.10\n",
       "71+        0.10\n",
       "Unknown    0.05\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(bd.groupby(\"age_band\")[\"y\"].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unknown</th>\n",
       "      <th>ab_10</th>\n",
       "      <th>ab_11</th>\n",
       "      <th>ab_13</th>\n",
       "      <th>ab_17</th>\n",
       "      <th>ab_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unknown  ab_10  ab_11  ab_13  ab_17  ab_9\n",
       "0        0      1      0      0      0     0\n",
       "1        0      0      1      0      0     0\n",
       "2        0      0      1      0      0     0\n",
       "3        0      0      0      0      1     0\n",
       "4        0      1      0      0      0     0"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(bd)):\n",
    "    if bd[\"age_band\"][i] in [\"71+\",\"65-70\",\"51-55\",\"45-50\"]:\n",
    "        bd.loc[i,\"age_band\"]=\"ab_10\"\n",
    "    if bd[\"age_band\"][i] in [\"55-60\",\"41-45\",\"31-35\",\"22-25\",\"26-30\"]:\n",
    "        bd.loc[i,\"age_band\"]=\"ab_11\"\n",
    "    if bd[\"age_band\"][i]==\"36-40\":\n",
    "        bd.loc[i,\"age_band\"]=\"ab_13\"\n",
    "    if bd[\"age_band\"][i]==\"18-21\":\n",
    "        bd.loc[i,\"age_band\"]=\"ab_17\"\n",
    "    if bd[\"age_band\"][i]==\"61-65\":\n",
    "        bd.loc[i,\"age_band\"]=\"ab_9\"\n",
    "ab_dummies=pd.get_dummies(bd[\"age_band\"])\n",
    "ab_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add it back to the dataset, dropping the dummy for \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd=pd.concat([bd,ab_dummies],1)\n",
    "bd=bd.drop([\"age_band\",\"Unknown\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Partner                 7709\n",
       "Single/Never Married    1101\n",
       "Divorced/Separated       679\n",
       "Widowed                  618\n",
       "Unknown                   48\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd[\"st_partner\"]=np.where(bd[\"status\"]==\"Partner\",1,0)\n",
    "bd[\"st_singleNm\"]=np.where(bd[\"status\"]==\"Single/Never Married\",1,0)\n",
    "bd[\"st_divSep\"]=np.where(bd[\"status\"]==\"Divorced/Separated\",1,0)\n",
    "bd=bd.drop([\"status\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "Business Manager     0.12\n",
       "Housewife            0.09\n",
       "Manual Worker        0.11\n",
       "Other                0.11\n",
       "Professional         0.12\n",
       "Retired              0.10\n",
       "Secretarial/Admin    0.11\n",
       "Student              0.11\n",
       "Unknown              0.11\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(bd.groupby(\"occupation\")[\"y\"].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Housewife</th>\n",
       "      <th>oc_10</th>\n",
       "      <th>oc_11</th>\n",
       "      <th>oc_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Housewife  oc_10  oc_11  oc_12\n",
       "0          0      0      1      0\n",
       "1          0      1      0      0\n",
       "2          0      0      0      1\n",
       "3          0      0      0      1\n",
       "4          0      0      0      1"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(bd)):\n",
    "    if bd[\"occupation\"][i] in [\"Unknown\",\"Student\",\"Secretarial/Admin\",\"Other\",\"Manual Worker\"]:\n",
    "        bd.loc[i,\"occupation\"]=\"oc_11\"\n",
    "    if bd[\"occupation\"][i] in [\"Professional\",\"Business Manager\"]:\n",
    "        bd.loc[i,\"occupation\"]=\"oc_12\"\n",
    "    if bd[\"occupation\"][i]==\"Retired\":\n",
    "        bd.loc[i,\"occupation\"]=\"oc_10\"\n",
    "oc_dummies=pd.get_dummies(bd[\"occupation\"])\n",
    "oc_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd=pd.concat([bd,oc_dummies],1)\n",
    "\n",
    "bd=bd.drop([\"occupation\",\"Housewife\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation_partner\n",
       "Business Manager     0.11\n",
       "Housewife            0.11\n",
       "Manual Worker        0.11\n",
       "Other                0.10\n",
       "Professional         0.11\n",
       "Retired              0.10\n",
       "Secretarial/Admin    0.12\n",
       "Student              0.12\n",
       "Unknown              0.10\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(bd.groupby(\"occupation_partner\")[\"y\"].mean(),2) #here 2 means it is taking round off upto 2 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd[\"ocp_10\"]=0\n",
    "bd[\"ocp_12\"]=0\n",
    "for i in range(len(bd)):\n",
    "    if bd[\"occupation_partner\"][i] in [\"Unknown\",\"Retired\",\"Other\"]:\n",
    "        bd.loc[i,\"ocp_10\"]=1\n",
    "    if bd[\"occupation_partner\"][i] in [\"Student\",\"Secretarial/Admin\"]:\n",
    "        bd.loc[i,\"ocp_12\"]=1\n",
    "        \n",
    "bd=bd.drop([\"occupation_partner\",\"TVarea\",\"post_code\",\"post_area\",\"region\"],1)\n",
    "#you can create a different method(np.where) to create dummies,illustrated above and much easier than for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we have also dropped variables TVarea, region, post_code, post_area. If you look at number of unique values taken by post_area and post_code , you'll realise why decided to drop them. TVarea and region on the other hand we have left for you to make use of and see if using them improves your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Own Home                9413\n",
       "Rent from Council/HA     322\n",
       "Rent Privately           261\n",
       "Live in Parental Hom     109\n",
       "Unclassified              50\n",
       "Name: home_status, dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd[\"home_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd[\"hs_own\"]=np.where(bd[\"home_status\"]==\"Own Home\",1,0)\n",
    "del bd[\"home_status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we used an alternate syntax for dropping a column here. You can use that too if you like this syntax better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female     7634\n",
       "Male       2486\n",
       "Unknown      35\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd[\"gender_f\"]=np.where(bd[\"gender\"]==\"Female\",1,0)\n",
    "del bd[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     9436\n",
       "Yes     719\n",
       "Name: self_employed, dtype: int64"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd[\"self_employed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd[\"semp_yes\"]=np.where(bd[\"self_employed\"]==\"Yes\",1,0)\n",
    "del bd[\"self_employed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     9026\n",
       "Yes    1129\n",
       "Name: self_employed_partner, dtype: int64"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd[\"self_employed_partner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd[\"semp_part_yes\"]=np.where(bd[\"self_employed_partner\"]==\"Yes\",1,0)\n",
    "del bd[\"self_employed_partner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ">=35,000             2517\n",
       "<27,500, >=25,000    1227\n",
       "<30,000, >=27,500     994\n",
       "<25,000, >=22,500     833\n",
       "<20,000, >=17,500     683\n",
       "<12,500, >=10,000     677\n",
       "<17,500, >=15,000     634\n",
       "<15,000, >=12,500     629\n",
       "<22,500, >=20,000     590\n",
       "<10,000, >= 8,000     563\n",
       "< 8,000, >= 4,000     402\n",
       "< 4,000               278\n",
       "Unknown               128\n",
       "Name: family_income, dtype: int64"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd[\"family_income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert this to number as average of the range once we have figured out what to do with category \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family_income\n",
       "< 4,000              0.0755\n",
       "< 8,000, >= 4,000    0.0796\n",
       "<10,000, >= 8,000    0.1066\n",
       "<12,500, >=10,000    0.1019\n",
       "<15,000, >=12,500    0.1113\n",
       "<17,500, >=15,000    0.1230\n",
       "<20,000, >=17,500    0.1113\n",
       "<22,500, >=20,000    0.1186\n",
       "<25,000, >=22,500    0.1032\n",
       "<27,500, >=25,000    0.0970\n",
       "<30,000, >=27,500    0.1157\n",
       ">=35,000             0.1116\n",
       "Unknown              0.0703\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(bd.groupby(\"family_income\")[\"y\"].mean(),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd[\"fi\"]=4 # by doing this , we have essentially clubbed <4000 and Unknown values . How?\n",
    "bd.loc[bd[\"family_income\"]==\"< 8,000, >= 4,000\",\"fi\"]=6\n",
    "bd.loc[bd[\"family_income\"]==\"<10,000, >= 8,000\",\"fi\"]=9\n",
    "bd.loc[bd[\"family_income\"]==\"<12,500, >=10,000\",\"fi\"]=11.25\n",
    "bd.loc[bd[\"family_income\"]==\"<15,000, >=12,500\",\"fi\"]=13.75\n",
    "bd.loc[bd[\"family_income\"]==\"<17,500, >=15,000\",\"fi\"]=16.25\n",
    "bd.loc[bd[\"family_income\"]==\"<20,000, >=17,500\",\"fi\"]=18.75\n",
    "bd.loc[bd[\"family_income\"]==\"<22,500, >=20,000\",\"fi\"]=21.25\n",
    "bd.loc[bd[\"family_income\"]==\"<25,000, >=22,500\",\"fi\"]=23.75\n",
    "bd.loc[bd[\"family_income\"]==\"<27,500, >=25,000\",\"fi\"]=26.25\n",
    "bd.loc[bd[\"family_income\"]==\"<30,000, >=27,500\",\"fi\"]=28.75\n",
    "bd.loc[bd[\"family_income\"]==\">=35,000\",\"fi\"]=35\n",
    "bd=bd.drop([\"family_income\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REF_NO                               int64\n",
       "children                             int64\n",
       "year_last_moved                      int64\n",
       "Average Credit Card Transaction    float64\n",
       "Balance Transfer                   float64\n",
       "Term Deposit                       float64\n",
       "Life Insurance                     float64\n",
       "Medical Insurance                  float64\n",
       "Average A/C Balance                float64\n",
       "Personal Loan                      float64\n",
       "Investment in Mutual Fund          float64\n",
       "Investment Tax Saving Bond         float64\n",
       "Home Loan                          float64\n",
       "Online Purchase Amount             float64\n",
       "Investment in Commudity            float64\n",
       "Investment in Equity               float64\n",
       "Investment in Derivative           float64\n",
       "Portfolio Balance                  float64\n",
       "y                                    int32\n",
       "ab_10                                uint8\n",
       "ab_11                                uint8\n",
       "ab_13                                uint8\n",
       "ab_17                                uint8\n",
       "ab_9                                 uint8\n",
       "st_partner                           int32\n",
       "st_singleNm                          int32\n",
       "st_divSep                            int32\n",
       "oc_10                                uint8\n",
       "oc_11                                uint8\n",
       "oc_12                                uint8\n",
       "ocp_10                               int64\n",
       "ocp_12                               int64\n",
       "hs_own                               int32\n",
       "gender_f                             int32\n",
       "semp_yes                             int32\n",
       "semp_part_yes                        int32\n",
       "fi                                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the entire data is of numeric type, lets beging our modelling process after removing nas from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.dropna(axis=0,inplace=True)\n",
    "bd_train, bd_test = train_test_split(bd, test_size = 0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=bd_train.drop([\"y\",\"REF_NO\"],1)\n",
    "y_train=bd_train[\"y\"]\n",
    "x_test=bd_test.drop([\"y\",\"REF_NO\"],1)\n",
    "y_test=bd_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr=LogisticRegression(penalty=\"l1\",class_weight=\"balanced\",random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=2,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8995918649695628"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score model performance on the test data\n",
    "roc_auc_score(y_test,logr.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To arrive at the eventual 1,0 prediction , we need to find some way [some cutoff ] to convert predicted probabilites into two classes. Lets first get the probabilities out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-412-94d54c438e0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprob_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlogr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "prob_score=pd.Series(list(zip(*logr.predict_proba(x_train)))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On these scores , we will consider many cutoffs between 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0,1,100) #cutoff is a random values between 0 and 1,there is no relation of cutoff with code. You need to define it everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these cutoff , we are going to look at TP,FP,TN,FN values and caluclate KS. Then we'll chose the best cutoff as the one having highest KS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_cut=[]\n",
    "for cutoff in cutoffs:\n",
    "    predicted=pd.Series([0]*len(y_train))#here we are creating a series(dataframe) whose count is equals to y_train.\n",
    "    predicted[prob_score>cutoff]=1\n",
    "    df=pd.DataFrame(list(zip(y_train,predicted)),columns=[\"real\",\"predicted\"])\n",
    "    TP=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==1) ])\n",
    "    FP=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==1) ])\n",
    "    TN=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==0) ])\n",
    "    FN=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==0) ])\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    KS=(TP/P)-(FP/N)\n",
    "    KS_cut.append(KS)\n",
    "\n",
    "cutoff_data=pd.DataFrame(list(zip(cutoffs,KS_cut)),columns=[\"cutoff\",\"KS\"])\n",
    "\n",
    "KS_cutoff=cutoff_data[cutoff_data[\"KS\"]==cutoff_data[\"KS\"].max()][\"cutoff\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll see how this model with the cutoff determined here , performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home work--- find the KS score where F1 SCORE is maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on test data\n",
    "prob_score_test=pd.Series(list(zip(*logr.predict_proba(x_test)))[1])\n",
    "\n",
    "predicted_test=pd.Series([0]*len(y_test))#to be decoded thi line\n",
    "predicted_test[prob_score_test>float(KS_cutoff)]=1\n",
    "\n",
    "df_test=pd.DataFrame(list(zip(y_test,predicted_test)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "k=pd.crosstab(df_test['real'],df_test[\"predicted\"])\n",
    "print('confusion matrix :\\n \\n ',k)\n",
    "TN=k.iloc[0,0]\n",
    "TP=k.iloc[1,1]\n",
    "FP=k.iloc[0,1]\n",
    "FN=k.iloc[1,0]\n",
    "P=TP+FN\n",
    "N=TN+FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of test\n",
    "(TP+TN)/(P+N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity on test\n",
    "TP/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specificity on test\n",
    "TN/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we see how cutoff determined by F_beta score performs on test data for beta values : 0.5,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0.010,0.99,100)\n",
    "def Fbeta_perf(beta,cutoffs,y_train,prob_score):\n",
    "    FB_cut=[]\n",
    "    for cutoff in cutoffs:\n",
    "        predicted=pd.Series([0]*len(y_train))\n",
    "        predicted[prob_score>cutoff]=1\n",
    "        df=pd.DataFrame(list(zip(y_train,predicted)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "        TP=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==1) ])\n",
    "        FP=len(df[(df[\"real\"]==0) &(df[\"predicted\"]==1) ])\n",
    "        FN=len(df[(df[\"real\"]==1) &(df[\"predicted\"]==0) ])\n",
    "        P=TP+FN\n",
    "        \n",
    "        \n",
    "        Precision=TP/(TP+FP)\n",
    "        Recall=TP/P\n",
    "        FB=(1+beta**2)*Precision*Recall/((beta**2)*Precision+Recall)\n",
    "        FB_cut.append(FB)\n",
    "\n",
    "    cutoff_data=pd.DataFrame(list(zip(cutoffs,FB_cut)),columns=[\"cutoff\",\"FB\"])\n",
    "\n",
    "    FB_cutoff=cutoff_data[cutoff_data[\"FB\"]==cutoff_data[\"FB\"].max()][\"cutoff\"]\n",
    "\n",
    "    prob_score_test=pd.Series(list(zip(*logr.predict_proba(x_test)))[1])\n",
    "\n",
    "    predicted_test=pd.Series([0]*len(y_test))\n",
    "    predicted_test[prob_score_test>float(FB_cutoff)]=1\n",
    "\n",
    "    df_test=pd.DataFrame(list(zip(y_test,predicted_test)),columns=[\"real\",\"predicted\"])\n",
    "\n",
    "    k=pd.crosstab(df_test['real'],df_test[\"predicted\"])\n",
    "#     print('confusion matrix :\\n \\n ',k)\n",
    "    TN=k.iloc[0,0]\n",
    "    TP=k.iloc[1,1]\n",
    "    FP=k.iloc[0,1]\n",
    "    FN=k.iloc[1,0]\n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    print('For beta :',beta)\n",
    "    print('Accuracy is :',(TP+TN)/(P+N))\n",
    "    print('Sensitivity is :',(TP/P))\n",
    "    print('Specificity is :',(TN/N))\n",
    "    print('\\n \\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fbeta_perf(0.5,cutoffs,y_train,prob_score)\n",
    "Fbeta_perf(1,cutoffs,y_train,prob_score)\n",
    "Fbeta_perf(2,cutoffs,y_train,prob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that low beta < 1 favors Specificity where as beta > 1 favors sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll conclude our discussion here. Please do the practice exercises . If you face any issue we'll discuss that either in class or QA forum on LMS.\n",
    "\n",
    "Prepared By : Lalit Sachan (lalit.sachan@edvancer.in)\n",
    "\n",
    "In case of any doubts or errata alert; please take to QA forum for discussion.\n",
    "\n",
    "Doubts will be discussed in live class sessions too. [This doesnt apply for self paced students]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
